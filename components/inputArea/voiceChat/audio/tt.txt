"use client";

import React, { useEffect, useRef, useState } from "react";
import { Icon } from "@iconify/react";
import Image from "next/image";

interface VoiceChatProps {
  isOpen: boolean;
  onClose: () => void;
  onSendVoiceMessage?: (audioBlob: Blob) => void;
}

// Fayl hajmini nazorat qilish uchun konstantalar
const MAX_RECORDING_SECONDS = 30; // Maksimal yozib olish vaqti (soniya)
const AUDIO_BITRATE = 96000; // 96 kbps - nutq uchun yaxshi sifat va kichik hajm

export default function VoiceChat({ isOpen, onClose }: VoiceChatProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);
  const [aiResponse, setAiResponse] = useState("");
  const [recordingTime, setRecordingTime] = useState(0);

  // Ref'lar
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameIdRef = useRef<number | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);

  // To'liq tozalash funksiyasi
  const cleanup = () => {
    if (animationFrameIdRef.current) {
      cancelAnimationFrame(animationFrameIdRef.current);
      animationFrameIdRef.current = null;
    }
    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => track.stop());
      mediaStreamRef.current = null;
    }
    if (audioContextRef.current && audioContextRef.current.state !== "closed") {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    analyserRef.current = null;
    mediaRecorderRef.current = null;
    audioChunksRef.current = [];
    setAudioLevel(0);
    setIsRecording(false);
    setRecordingTime(0);
  };

  // Yozib olishni boshlash
  const startRecording = async () => {
    if (!navigator.mediaDevices?.getUserMedia) {
      alert(
        "Mikrofonni ishlatish uchun xavfsiz (HTTPS) ulanish talab etiladi."
      );
      return;
    }

    // Oldingi holatlarni tozalash
    setAiResponse("");

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 44100,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });
      mediaStreamRef.current = stream;

      const audioContext = new AudioContext();
      audioContextRef.current = audioContext;
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      analyserRef.current = analyser;

      // Server uchun eng mos formatni tanlash - FAQAT WAV va MP3 qo'llab-quvvatlanadi
      let mimeType = "";

      // 1. Avval WAV formatini sinab ko'ramiz (server tomonidan qo'llab-quvvatlanadi)
      if (MediaRecorder.isTypeSupported("audio/wav")) {
        mimeType = "audio/wav";
      }
      // 2. Agar WAV bo'lmasa, MP3 ni sinab ko'ramiz
      else if (MediaRecorder.isTypeSupported("audio/mpeg")) {
        mimeType = "audio/mpeg"; // MP3 format
      }
      // 3. Fallback - WebM (keyinroq WAV ga convert qilamiz)
      else if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) {
        mimeType = "audio/webm;codecs=opus";
      } else if (MediaRecorder.isTypeSupported("audio/webm")) {
        mimeType = "audio/webm";
      }
      // 4. Oxirgi variant - MP4 (keyinroq convert qilamiz)
      else if (MediaRecorder.isTypeSupported("audio/mp4")) {
        mimeType = "audio/mp4";
      }

      console.log("Using MIME type:", mimeType);

      const options: MediaRecorderOptions = mimeType
        ? {
            mimeType: mimeType,
            audioBitsPerSecond: AUDIO_BITRATE,
          }
        : {
            audioBitsPerSecond: AUDIO_BITRATE,
          };

      const mediaRecorder = new MediaRecorder(stream, options);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const finalMimeType = mediaRecorder.mimeType || mimeType || "audio/wav";
        let audioBlob = new Blob(audioChunksRef.current, {
          type: finalMimeType,
        });

        console.log("Original audio blob:", {
          type: audioBlob.type,
          size: audioBlob.size,
          mimeType: finalMimeType,
        });

        // Agar server qo'llab-quvvatlamaydigan format bo'lsa, WAV ga convert qilamiz
        if (
          finalMimeType.includes("webm") ||
          finalMimeType.includes("ogg") ||
          finalMimeType.includes("mp4") ||
          finalMimeType.includes("m4a")
        ) {
          try {
            console.log("Converting to WAV (server only supports wav/mp3)...");
            audioBlob = await convertWebMToWav(audioBlob);
            console.log("Converted to WAV:", {
              type: audioBlob.type,
              size: audioBlob.size,
            });
          } catch (error) {
            console.error("Conversion failed, cannot proceed:", error);
            // Server faqat wav/mp3 qabul qilgani uchun convert qila olmasak, xato
            throw new Error(
              "Audio format conversion failed - server only accepts wav/mp3"
            );
          }
        }

        sendAudioToApi(audioBlob);
        cleanup();
      };

      mediaRecorder.start(1000); // Har soniyada chunk olish
      setIsRecording(true);
      visualize();

      // Yozib olish vaqtini hisoblash va cheklash
      setRecordingTime(0);
      recordingIntervalRef.current = setInterval(() => {
        setRecordingTime((prev) => {
          if (prev + 1 >= MAX_RECORDING_SECONDS) {
            stopRecording();
          }
          return prev + 1;
        });
      }, 1000);
    } catch (err) {
      console.error("Mikrofon bilan ishlashda xatolik:", err);
      alert(
        "Mikrofonga ruxsat berilmadi yoki boshqa xatolik yuz berdi. Konsolni tekshiring."
      );
      cleanup();
    }
  };

  // Yozib olishni to'xtatish
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
    }
  };

  // Audio vizualizatori
  const visualize = () => {
    if (!analyserRef.current) return;
    const analyser = analyserRef.current;
    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    const loop = () => {
      animationFrameIdRef.current = requestAnimationFrame(loop);
      analyser.getByteFrequencyData(dataArray);
      const average =
        dataArray.reduce((acc, val) => acc + val, 0) / dataArray.length;
      setAudioLevel(average);
    };
    loop();
  };

  // Blobni toza base64 formatiga o'tkazish
  const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result as string;
        // "data:audio/webm;base64," kabi prefiksni olib tashlaymiz
        const base64Data = result.split(",")[1];
        resolve(base64Data);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  };

  // WebM ni WAV ga convert qilish funksiyasi
  const convertWebMToWav = async (webmBlob: Blob): Promise<Blob> => {
    return new Promise((resolve, reject) => {
      const audioContext = new (window.AudioContext ||
        (window as any).webkitAudioContext)();
      const fileReader = new FileReader();

      fileReader.onload = async () => {
        try {
          const arrayBuffer = fileReader.result as ArrayBuffer;
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          // WAV formatiga convert qilish
          const wav = audioBufferToWav(audioBuffer);
          const wavBlob = new Blob([wav], { type: "audio/wav" });

          audioContext.close();
          resolve(wavBlob);
        } catch (error) {
          console.error("Audio convert error:", error);
          audioContext.close();
          reject(error);
        }
      };

      fileReader.onerror = reject;
      fileReader.readAsArrayBuffer(webmBlob);
    });
  };

  // AudioBuffer ni WAV formatiga convert qilish
  const audioBufferToWav = (buffer: AudioBuffer): ArrayBuffer => {
    const length = buffer.length;
    const sampleRate = buffer.sampleRate;
    const channels = buffer.numberOfChannels;

    const arrayBuffer = new ArrayBuffer(44 + length * channels * 2);
    const view = new DataView(arrayBuffer);

    // WAV header yozish
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };

    writeString(0, "RIFF");
    view.setUint32(4, 36 + length * channels * 2, true);
    writeString(8, "WAVE");
    writeString(12, "fmt ");
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, channels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * channels * 2, true);
    view.setUint16(32, channels * 2, true);
    view.setUint16(34, 16, true);
    writeString(36, "data");
    view.setUint32(40, length * channels * 2, true);

    // Audio data yozish
    let offset = 44;
    for (let i = 0; i < length; i++) {
      for (let channel = 0; channel < channels; channel++) {
        const sample = Math.max(
          -1,
          Math.min(1, buffer.getChannelData(channel)[i])
        );
        view.setInt16(
          offset,
          sample < 0 ? sample * 0x8000 : sample * 0x7fff,
          true
        );
        offset += 2;
      }
    }

    return arrayBuffer;
  };

  // Audioni API'ga yuborish
  const sendAudioToApi = async (audioBlob: Blob) => {
    setIsProcessing(true);
    setAiResponse("");

    try {
      const base64Audio = await blobToBase64(audioBlob);

      // Format ni blob type'ga qarab belgilash
      let format = "wav"; // Default WAV
      if (audioBlob.type.includes("mp4")) {
        format = "m4a";
      } else if (audioBlob.type.includes("mp3")) {
        format = "mp3";
      } else if (audioBlob.type.includes("wav")) {
        format = "wav";
      }

      console.log("Sending audio to API:", {
        type: audioBlob.type,
        size: audioBlob.size,
        format: format,
        base64Length: base64Audio.length,
      });

      const payload = {
        model: "voxtral",
        messages: [
          {
            role: "user",
            content: [
              {
                type: "input_audio",
                input_audio: {
                  data: base64Audio,
                  format: format,
                },
              },
            ],
          },
        ],
        stream: true,
      };

      console.log("Request payload format:", format);

      const response = await fetch(
        `/api/voice-proxy/v1-openai/chat/completions`, // next.config.ts proxy uchun
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer gpustack_492d76cbf4965096_05640baafe45e86162294815a9489e6e`,
          },
          body: JSON.stringify(payload),
        }
      );

      console.log("Response status:", response.status);

      if (!response.ok) {
        const errorText = await response.text();
        console.error("Server error response:", errorText);

        let errorMessage = `Server xatosi: ${response.status} ${response.statusText}`;
        try {
          const errorJson = JSON.parse(errorText);
          if (errorJson.error && errorJson.error.message) {
            errorMessage += `. Sabab: ${errorJson.error.message}`;
          }
        } catch (e) {
          errorMessage += `. Batafsil: ${errorText}`;
        }

        throw new Error(errorMessage);
      }

      if (!response.body) {
        throw new Error("Javob tanasi bo'sh");
      }

      // Streaming javobni o'qish - chunk'larni to'g'ri birlashtirish
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let done = false;
      let fullResponse = "";
      let buffer = ""; // Yarim qolgan chunk'larni saqlash uchun

      while (!done) {
        const { value, done: readerDone } = await reader.read();
        done = readerDone;

        if (value) {
          const chunk = decoder.decode(value, { stream: true });
          buffer += chunk; // Bufferga qo'shamiz

          // To'liq satr(lar)ni ajratamiz
          const lines = buffer.split("\n");

          // Oxirgi element yarim bo'lishi mumkin, uni bufferda qoldiramiz
          buffer = lines.pop() || "";

          // To'liq satrlarni qayta ishlaymiz
          for (const line of lines) {
            if (line.trim() && line.startsWith("data: ")) {
              const data = line.substring(6).trim();
              if (data === "[DONE]") {
                done = true;
                break;
              }

              // Bo'sh yoki noto'g'ri data'ni o'tkazib yuborish
              if (!data || data.length < 2) continue;

              try {
                const parsed = JSON.parse(data);
                const content = parsed.choices?.[0]?.delta?.content || "";
                if (content) {
                  fullResponse += content;
                  setAiResponse(fullResponse);
                }
              } catch (e) {
                console.warn(
                  "JSON parse warning (yarim chunk bo'lishi mumkin):",
                  e.message
                );
                console.warn("Problematic data:", data);
                // JSON parse qila olmagan chunk'ni o'tkazib yuboramiz
                continue;
              }
            }
          }
        }
      }

      // Oxirgi bufferda qolgan ma'lumotni ham tekshiramiz
      if (buffer.trim() && buffer.startsWith("data: ")) {
        const data = buffer.substring(6).trim();
        if (data && data !== "[DONE]") {
          try {
            const parsed = JSON.parse(data);
            const content = parsed.choices?.[0]?.delta?.content || "";
            if (content) {
              fullResponse += content;
              setAiResponse(fullResponse);
            }
          } catch (e) {
            console.warn("Final buffer parse warning:", e.message);
          }
        }
      }

      if (!fullResponse.trim()) {
        setAiResponse("AI'dan javob olinmadi. Iltimos, qayta urinib ko'ring.");
      }
    } catch (error) {
      console.error("Full error:", error);
      const errorMessage =
        error instanceof Error ? error.message : "Noma'lum xato";
      setAiResponse(`Xatolik yuz berdi: ${errorMessage}`);
    } finally {
      setIsProcessing(false);
    }
  };

  const handleToggleRecording = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  const handleClose = () => {
    if (isRecording) {
      stopRecording();
    }
    cleanup();
    setAiResponse("");
    setIsProcessing(false);
    onClose();
  };

  useEffect(() => {
    // Komponent yo'q qilinganda resurslarni tozalash
    return () => {
      cleanup();
    };
  }, []);

  // ESC tugmasini bosishda yopish
  useEffect(() => {
    const handleKeyDown = (event: KeyboardEvent) => {
      if (event.key === "Escape" && isOpen) {
        handleClose();
      }
    };

    if (isOpen) {
      document.addEventListener("keydown", handleKeyDown);
    }

    return () => {
      document.removeEventListener("keydown", handleKeyDown);
    };
  }, [isOpen]);

  if (!isOpen) return null;

  return (
    <div className="fixed inset-0 bg-[#00071C] z-50 flex flex-col items-center justify-center text-white">
      {/* Animatsiya */}
      <div className="absolute top-0">
        <Image
          src="https://cdn.dribbble.com/userupload/24087657/file/original-94d180707ef3b05419ec4666226a6e0d.gif"
          alt="voice-anim"
          width={608}
          height={508}
          className="rounded-full shadow-2xl"
          style={{
            transform: `scale(${1 + audioLevel / 250})`,
            transition: "transform 0.1s ease-out",
          }}
        />
      </div>

      {/* Matn va holat */}
      <div className="absolute top-20 text-center px-4 max-w-2xl w-full">
        {isRecording && (
          <div className="mb-4">
            <p className="text-lg text-blue-400 mb-2">
              🎤 Gapiring... ({recordingTime}s / {MAX_RECORDING_SECONDS}s)
            </p>
            <div className="w-full bg-gray-700 rounded-full h-2">
              <div
                className="bg-blue-600 h-2 rounded-full transition-all duration-1000"
                style={{
                  width: `${(recordingTime / MAX_RECORDING_SECONDS) * 100}%`,
                }}
              ></div>
            </div>
          </div>
        )}

        {isProcessing && (
          <div className="mb-4">
            <p className="text-lg text-yellow-400 mb-2">
              ⏳ AI javob tayyorlayapti...
            </p>
            <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-yellow-400 mx-auto"></div>
          </div>
        )}

        {aiResponse && (
          <div className="bg-black/40 p-4 rounded-lg max-h-60 overflow-y-auto backdrop-blur-sm border border-white/10">
            <div className="flex items-start gap-2 mb-2">
              <Icon
                icon="mdi:robot"
                className="w-5 h-5 text-blue-400 mt-1 flex-shrink-0"
              />
              <p className="text-sm text-gray-200 text-left leading-relaxed">
                {aiResponse}
              </p>
            </div>
          </div>
        )}
      </div>

      {/* Tugmalar */}
      <div className="absolute bottom-8">
        <div className="flex items-center gap-6">
          <button
            onClick={handleToggleRecording}
            disabled={isProcessing}
            className={`w-16 h-16 rounded-full flex items-center justify-center shadow-lg transition-all duration-200 border-2 ${
              isRecording
                ? "bg-red-600/80 hover:bg-red-600 border-red-400 animate-pulse"
                : "bg-blue-600/80 hover:bg-blue-600 border-blue-400"
            } ${
              isProcessing
                ? "opacity-50 cursor-not-allowed"
                : "cursor-pointer hover:scale-105"
            }`}
          >
            <Icon
              icon={isRecording ? "mdi:stop" : "mdi:microphone"}
              className="w-7 h-7 text-white"
            />
          </button>

          <button
            onClick={handleClose}
            className="w-16 h-16 bg-gray-600/80 hover:bg-gray-600 border-2 border-gray-400 rounded-full flex items-center justify-center cursor-pointer hover:scale-105 transition-all duration-200"
          >
            <Icon icon="mdi:close" className="w-7 h-7 text-white" />
          </button>
        </div>

        <div className="text-center mt-4">
          <p className="text-xs text-gray-400">ESC - Yopish</p>
        </div>
      </div>
    </div>
  );
}

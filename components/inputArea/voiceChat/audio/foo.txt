"use client";

import React, { useEffect, useRef, useState, useCallback } from "react";
import { Icon } from "@iconify/react";
import Image from "next/image";
import { LiveAudioVisualizer, AudioVisualizer } from "react-audio-visualize";

interface VoiceChatProps {
  isOpen: boolean;
  onClose: () => void;
}

export default function VoiceChat({ isOpen, onClose }: VoiceChatProps) {
  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(
    null
  );
  const [recordedBlob, setRecordedBlob] = useState<Blob | null>(null);
  const [isPlaying, setIsPlaying] = useState<boolean>(false);

  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const visualize = useCallback(() => {
    const analyser = analyserRef.current;
    if (!analyser || !isRecording) return;

    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    const loop = () => {
      if (!analyser || !isRecording) return;

      analyser.getByteFrequencyData(dataArray);
      const average =
        dataArray.reduce((acc, val) => acc + val, 0) / dataArray.length;
      setAudioLevel(average);
      animationFrameRef.current = requestAnimationFrame(loop);
    };

    loop();
  }, [isRecording]);

  const stopRecording = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    if (mediaRecorder && mediaRecorder.state === "recording") {
      mediaRecorder.stop();
    }

    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => track.stop());
      mediaStreamRef.current = null;
    }

    if (audioContextRef.current && audioContextRef.current.state !== "closed") {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    analyserRef.current = null;
    setMediaRecorder(null);
    setAudioLevel(0);
  }, [mediaRecorder]);

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
        },
      });

      mediaStreamRef.current = stream;
      audioChunksRef.current = [];

      // Audio Context va Analyser yaratish
      const audioContext = new (window.AudioContext ||
        (window as any).webkitAudioContext)();
      audioContextRef.current = audioContext;

      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.8;

      source.connect(analyser);
      analyserRef.current = analyser;

      // MediaRecorder yaratish
      let mimeType = "audio/webm;codecs=opus";
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = "audio/webm";
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = "audio/mp4";
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = "audio/wav";
          }
        }
      }

      const recorder = new MediaRecorder(
        stream,
        mimeType ? { mimeType } : undefined
      );

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      recorder.onstop = () => {
        const blob = new Blob(audioChunksRef.current, {
          type: mimeType || "audio/webm",
        });
        setRecordedBlob(blob);
      };

      recorder.onerror = (event) => {
        console.error("MediaRecorder error:", event);
        setIsRecording(false);
      };

      recorder.start(100);
      setMediaRecorder(recorder);

      // Visualizatsiyani boshlash
      setTimeout(() => {
        visualize();
      }, 100);
    } catch (err) {
      console.error("Mikrofon bilan muammo:", err);
      setIsRecording(false);
      alert("Mikrofon ruxsati berilmadi yoki xatolik yuz berdi!");
    }
  }, [visualize]);

  useEffect(() => {
    if (isRecording && isOpen) {
      startRecording();
    } else {
      stopRecording();
    }

    return () => {
      stopRecording();
    };
  }, [isRecording, isOpen, startRecording, stopRecording]);

  const handleToggleRecording = () => {
    if (isRecording) {
      setIsRecording(false);
    } else {
      setRecordedBlob(null);
      audioChunksRef.current = [];
      setIsRecording(true);
    }
  };

  const handlePlayPause = () => {
    if (recordedBlob && audioRef.current) {
      if (isPlaying) {
        audioRef.current.pause();
      } else {
        audioRef.current.play();
      }
    }
  };

  const handleDownload = () => {
    if (recordedBlob) {
      const url = URL.createObjectURL(recordedBlob);
      const a = document.createElement("a");
      a.href = url;
      a.download = `voice-recording-${new Date().getTime()}.webm`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
    }
  };

  const handleDelete = () => {
    setRecordedBlob(null);
    audioChunksRef.current = [];
    setIsPlaying(false);
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
    }
  };

  if (!isOpen) return null;

  return (
    <div className="fixed inset-0 bg-[#00071C] z-50 flex flex-col items-center justify-center text-white">
      {/* ANIMATED GIF */}
      <div className="absolute top-0">
        <Image
          src="https://cdn.dribbble.com/userupload/24087657/file/original-94d180707ef3b05419ec4666226a6e0d.gif"
          alt="voice-anim"
          width={608}
          height={508}
          className="rounded-full shadow-2xl"
          style={{
            transform: `scale(${1 + audioLevel / 250})`,
            transition: "transform 0.1s ease-out",
          }}
        />
      </div>

      {/* STATUS TEXT */}
      <div className="absolute top-20 text-center">
        <h2 className="text-2xl font-bold mb-2">
          {isRecording
            ? "Yozish..."
            : recordedBlob
            ? "Yozish tugadi"
            : "Ovoz yozish"}
        </h2>
        <p className="text-gray-300">
          {isRecording
            ? "Gapiring, ovozingiz yozilmoqda..."
            : recordedBlob
            ? "Audio tayyor, eshitish yoki yuklab olish mumkin"
            : "Yozishni boshlash uchun mikrofon tugmasini bosing"}
        </p>
      </div>

      {/* LIVE AUDIO VISUALIZER - MediaRecorder bilan */}
      {isRecording && mediaRecorder && (
        <div className="absolute bottom-72 w-full flex justify-center">
          <div className="bg-black/30 rounded-lg p-4 backdrop-blur-sm">
            <LiveAudioVisualizer
              mediaRecorder={mediaRecorder}
              width={300}
              height={60}
              barColor="#22d3ee"
              barWidth={4}
              gap={2}
              backgroundColor="transparent"
            />
          </div>
        </div>
      )}

      {/* RECORDED AUDIO VISUALIZER - yozish tugagandan keyin */}
      {recordedBlob && !isRecording && (
        <div className="absolute bottom-72 w-full flex justify-center">
          <div className="bg-black/30 rounded-lg p-4 backdrop-blur-sm">
            <AudioVisualizer
              blob={recordedBlob}
              width={400}
              height={80}
              barWidth={2}
              gap={1}
              barColor={isPlaying ? "#10b981" : "#22d3ee"}
              backgroundColor="transparent"
            />
          </div>
        </div>
      )}

      {/* AUDIO ELEMENT */}
      {recordedBlob && (
        <audio
          ref={audioRef}
          src={URL.createObjectURL(recordedBlob)}
          onPlay={() => setIsPlaying(true)}
          onPause={() => setIsPlaying(false)}
          onEnded={() => setIsPlaying(false)}
          style={{ display: "none" }}
        />
      )}

      {/* CONTROL BUTTONS */}
      <div className="absolute bottom-8">
        <div className="flex items-center gap-4">
          {/* Record/Stop Button */}
          <button
            onClick={handleToggleRecording}
            className={`w-16 h-16 rounded-full flex items-center justify-center shadow-lg transition-all duration-200 border-2 cursor-pointer ${
              isRecording
                ? "bg-red-600 hover:bg-red-700 border-red-400 animate-pulse"
                : "bg-blue-600 hover:bg-blue-700 border-blue-400"
            }`}
          >
            <Icon
              icon={isRecording ? "mdi:stop" : "mdi:microphone"}
              className="w-8 h-8 text-white"
            />
          </button>

          {/* Play/Pause Button */}
          {recordedBlob && !isRecording && (
            <button
              onClick={handlePlayPause}
              className="w-14 h-14 bg-green-600 hover:bg-green-700 border-2 border-green-400 rounded-full flex items-center justify-center cursor-pointer transition-all duration-200"
            >
              <Icon
                icon={isPlaying ? "mdi:pause" : "mdi:play"}
                className="w-6 h-6 text-white"
              />
            </button>
          )}

          {/* Download Button */}
          {recordedBlob && !isRecording && (
            <button
              onClick={handleDownload}
              className="w-14 h-14 bg-purple-600 hover:bg-purple-700 border-2 border-purple-400 rounded-full flex items-center justify-center cursor-pointer transition-all duration-200"
            >
              <Icon icon="mdi:download" className="w-6 h-6 text-white" />
            </button>
          )}

          {/* Delete Button */}
          {recordedBlob && !isRecording && (
            <button
              onClick={handleDelete}
              className="w-14 h-14 bg-red-600 hover:bg-red-700 border-2 border-red-400 rounded-full flex items-center justify-center cursor-pointer transition-all duration-200"
            >
              <Icon icon="mdi:delete" className="w-6 h-6 text-white" />
            </button>
          )}

          {/* Close Button */}
          <button
            onClick={onClose}
            className="w-14 h-14 bg-gray-600 hover:bg-gray-700 border-2 border-gray-400 rounded-full flex items-center justify-center cursor-pointer transition-all duration-200"
          >
            <Icon icon="mdi:close" className="w-6 h-6 text-white" />
          </button>
        </div>
      </div>

      {/* RECORDING TIMER */}
      {isRecording && (
        <div className="absolute bottom-32 bg-red-600/80 px-4 py-2 rounded-full">
          <div className="flex items-center gap-2">
            <div className="w-3 h-3 bg-white rounded-full animate-pulse"></div>
            <span className="text-white font-mono">REC</span>
          </div>
        </div>
      )}
    </div>
  );
}
